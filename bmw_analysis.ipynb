{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "great-sperm",
   "metadata": {},
   "source": [
    "# Objective\n",
    "Predict resale prices of BMW cars. This could for instance be used by someone who wants to sell their car, to get an idea about how much it is worth, similar to how Kelley Blue Book works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-joining",
   "metadata": {},
   "source": [
    "# Thinking about the problem\n",
    "From the readme of the dataset available here <https://github.com/datacamp/careerhub-data/tree/master/BMW%20Used%20Car%20Sales>, one can see that the dataset contains information about price, transmission, mileage, fuel type, road tax, miles per gallon (mpg), and engine size. Upon inspection of the dataset (see below), it turned out to additionally contain the car model and year (I'm assuming this means production year). First I want to describe my initial expectations for the relationships between these quantities, and formulate different levels of complexity for including the data.\n",
    "\n",
    "The five quantities model, year, transmission, fuel type, and engine size collectively describe the car configuration at the time of initial purchase. The quantity mileage describes how much the car has been used, and therefore worn since that point. The quantities miles per gallon and road tax should be given based on the new car configuration quantities.\n",
    "\n",
    "I suspect that the price will strongly depend on the mileage and age of the car, and a first simple model could therefore just consider these two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e48eee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This requires the file draw_diagrams.py to be in the same directory as this notebook\n",
    "import draw_diagrams\n",
    "draw_diagrams.data_model1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbbd40e",
   "metadata": {},
   "source": [
    "An improvement on this would be to include the new car configuration variables. From these in addition to price, mpg and road tax could be inferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77763c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_diagrams.data_model2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cec5fa",
   "metadata": {},
   "source": [
    "Finally the last two variables, mpg and road tax, can be included. These could affect the resale price of the car, since they would probably influence how much a buyer is willing to pay, but I suspect this connection will be less strong than the connection between the other variables and price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753404c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_diagrams.data_model3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b59be1b",
   "metadata": {},
   "source": [
    "Before any of this though, first I want to take a closer at the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7630ab74",
   "metadata": {},
   "source": [
    "\n",
    "# Loading and inspecting data\n",
    "First I load and inspect the data. I downloaded the data from [here](https://raw.githubusercontent.com/datacamp/careerhub-data/master/BMW%20Used%20Car%20Sales/bmw.csv) and saved it in the `datasets/bmw.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmw = pd.read_csv(\"datasets/bmw.csv\")\n",
    "bmw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-harassment",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmw.model.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmw.transmission.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmw.fuelType.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b214bfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in bmw:\n",
    "    print(col, len(bmw[col].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-laundry",
   "metadata": {},
   "source": [
    "# Data exploration\n",
    "<a id = \"data-exploration\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64de60b4",
   "metadata": {},
   "source": [
    "Let's look at how the price depends on all the continous variables using a pair plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467fd664",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(\n",
    "    bmw,  # hue='transmission',\n",
    "    x_vars=[\"price\", \"year\", \"mileage\", \"tax\", \"mpg\", \"engineSize\"],\n",
    "    y_vars=[\"price\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f74cdb8",
   "metadata": {},
   "source": [
    "There appears to be a definite relationship between price and both mileage and year. The relationship looks like at might be expopnential, so let's we look at the logarithm of the price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c108e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bmw_log = bmw.copy()\n",
    "bmw_log['log price'] = np.log10(bmw_log['price'])\n",
    "bmw_log = bmw_log.drop('price', axis='columns')\n",
    "\n",
    "sns.pairplot(bmw_log, #hue='transmission', \n",
    "             x_vars=['log price', 'year', 'mileage',  'tax', 'mpg', 'engineSize'],\n",
    "             y_vars=['log price']) #, hue='transmission')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571565f8",
   "metadata": {},
   "source": [
    "These plots reveal that there appears to be a linear relationship between the logarithm of the price, and both year and mileage. There is no obvious relationship between the price and the remaining variables, whether we consider logarithm or not. Going forward in the analysis, we will be using the logarithm of the price as the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f52f512",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "## Categorical variables\n",
    "Let us take a closer look at the categorical columns. First we print the number of values in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d0e3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\"model\", \"fuelType\", \"transmission\"]\n",
    "\n",
    "\n",
    "def print_categorical_counts(df, columns):\n",
    "    for col in columns:\n",
    "        display(df.groupby(col)[col].count())\n",
    "\n",
    "\n",
    "print_categorical_counts(bmw_log, categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8f6b14",
   "metadata": {},
   "source": [
    "There are a number of categories with very few records. For instance, the `fuelType` `Electric` has only three. With such a small amount of observations for this category, and no obvious relationship with other entries in this category as one naturally has for numeric columns, I wouldn't expect it to be possible to make reliable predictions for the selling price for this category. I therefore choose to drop any category with less than 10 records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b0a8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_almost_empty_categories(df, col, nmin=10):\n",
    "    df = df.copy()  # To avoid modyfiyng the input dataframe\n",
    "    category_count = df.groupby(col)[col].count()\n",
    "    for category_name, count in category_count.iteritems():\n",
    "        if count < nmin:\n",
    "            df = df[df[col] != category_name]\n",
    "    return df\n",
    "\n",
    "\n",
    "bmw_cat = bmw_log.copy()\n",
    "for col in categorical_columns:\n",
    "    bmw_cat = drop_almost_empty_categories(bmw_cat, col)\n",
    "bmw_cat[categorical_columns] = bmw_cat[categorical_columns].astype('category')\n",
    "# print_categorical_counts(bmw_cat, categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e005dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_car_config_cols = ['model', 'transmission', 'fuelType', 'engineSize']\n",
    "new_car_cols = new_car_config_cols + ['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fa0e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(\n",
    "    bmw.sort_values(\"engineSize\"),  # hue='transmission',\n",
    "    x_vars=new_car_cols,\n",
    "    y_vars=new_car_cols,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb752bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bmw_cat[bmw_cat.engineSize==0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9caed6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None):\n",
    "    new_car_grouped = bmw.groupby(new_car_cols)[[\"tax\", \"mpg\", \"price\"]]\n",
    "    display(new_car_grouped.nunique())\n",
    "    # display(bmw.groupby(new_car_config_cols)['tax'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95172c81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "choices = (\n",
    "    (bmw.model == \" 1 Series\")\n",
    "    & (bmw.transmission == \"Automatic\")\n",
    "    & (bmw.fuelType == \"Diesel\")\n",
    "    & (bmw.engineSize == 2.0)\n",
    "    & (bmw.year == 2016)\n",
    ")\n",
    "bmw[choices][[\"mileage\", \"tax\", \"mpg\", \"price\"]].sort_values(\"mileage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adadddcd",
   "metadata": {},
   "source": [
    "## A bit more data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b46d663",
   "metadata": {},
   "source": [
    "From the plots we can see that `mpg` has a group of values near 400, far from the nearest values which are less than 200. Let's see how many different values  are present there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023dfd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmw_cat[bmw_cat[\"mpg\"]>400][\"mpg\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aac1c16",
   "metadata": {},
   "source": [
    "All the values of `mpg` in the group near 400 have the same value. This looks very suspicious. I suspect this is data is wrong, and since it could seriously skew a model since it has such high values, I should eliminate these values (either impute with e.g. average, or drop the records all together).\n",
    "\n",
    "Let's also check the remaining two continous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f454d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(sorted(bmw_dropped[\"engineSize\"].unique()))\n",
    "display(bmw_cat.groupby(\"engineSize\")[\"engineSize\"].count())\n",
    "bmw_cat.groupby(\"tax\")[\"tax\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d66066",
   "metadata": {},
   "source": [
    "They both contain zeros, which seems weird for both tax and engine size. The skewing effect is probably less then for the `mpg` outliers, since zero is closer to other values of tax and engine size, but I should still either impute or drop these records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db1b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_dropped = (bmw_cat.mpg > 400) | (bmw_cat.engineSize == 0) | (bmw_cat.tax == 0)\n",
    "bmw_cleaned = bmw_cat[~to_be_dropped]\n",
    "# bmw_cleaned = bmw_log\n",
    "# bmw_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc79f9e0",
   "metadata": {},
   "source": [
    "# Regression models\n",
    "Here I train models on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafe21ae",
   "metadata": {},
   "source": [
    "## Linear regression models\n",
    "For the first model, I only want to consider the dependency of price on build year and mileage. From the plots in the [data exploration](#data-exploration) section we see that the logarithm of the price appears to depend linearly on year and mileage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0625f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def fit_and_test_linear_model(\n",
    "    df_selected, model=None, dependent=\"log price\", features=\"all\", \n",
    "    print_coeffs=True,\n",
    "    **kwargs\n",
    "):\n",
    "    if model is not None:\n",
    "        linreg = model\n",
    "    else:\n",
    "        linreg = LinearRegression()\n",
    "    linreg = fit_and_test_model(\n",
    "        df_selected, linreg, dependent=dependent, features=features, **kwargs\n",
    "    )\n",
    "    # print(features)\n",
    "    if print_coeffs:\n",
    "        if features == \"all\":\n",
    "            features = every_column_name_but(df_selected, dependent)\n",
    "        std = df_selected[features].std()\n",
    "        print_linear_coeffs(features, linreg, std)\n",
    "    return linreg\n",
    "\n",
    "\n",
    "def print_linear_coeffs(features, linreg, std):\n",
    "    coeffs = pd.DataFrame(\n",
    "        {\n",
    "            \"observable\": features,\n",
    "            \"coef\": linreg.coef_,\n",
    "            \"10^coef\": np.power(10, linreg.coef_),\n",
    "        }\n",
    "    )\n",
    "    coeffs[\"std\"] = std.values\n",
    "    coeffs['coef*std'] = coeffs['std'] * coeffs['coef']\n",
    "    coeffs = coeffs.sort_values(\"coef*std\", key=np.abs, ascending=False)\n",
    "    display(coeffs.set_index(\"observable\"))\n",
    "\n",
    "\n",
    "def normalize_df(\n",
    "    df,\n",
    "    columns=[\"year\"],\n",
    "    # columns=['year', 'mileage', 'tax', 'mpg', 'engineSize']\n",
    "):\n",
    "    columns = [col for col in columns if col in df.columns]\n",
    "    columns = [col for col in df.columns if col == \"log price\"]\n",
    "    df = df.copy()\n",
    "    if columns:\n",
    "        # print(df)\n",
    "        df_normed = pd.DataFrame(\n",
    "            data=StandardScaler().fit_transform(df[columns].values),\n",
    "            index=df.index,\n",
    "            columns=columns,\n",
    "        )\n",
    "        for col in columns:\n",
    "            df[col] = df_normed[col]\n",
    "        # print(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "def every_column_name_but(df, dependent):\n",
    "    features = [col for col in df.columns if col != dependent]\n",
    "    return features\n",
    "\n",
    "\n",
    "def split_dependent(df, features=\"all\", dependent=\"log price\"):\n",
    "    if features == \"all\":\n",
    "        features = every_column_name_but(df, dependent)\n",
    "    else:\n",
    "        features = [col for col in features if col in df.columns and col != dependent]\n",
    "    return df[features], df[dependent]\n",
    "\n",
    "\n",
    "def fit_and_test_model(\n",
    "    df, model, dependent=\"log price\", features=\"all\", plot_test=False\n",
    "):\n",
    "\n",
    "    # df_selected = normalize_df(df_selected)\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train, y_train = split_dependent(df_train, features, dependent=dependent)\n",
    "    X_test, y_test = split_dependent(df_test, features, dependent=dependent)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_predict_train = model.predict(X_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "\n",
    "    print(\n",
    "        \"Mean squared error, test: {:.2g}, train: {:.2g}\".format(\n",
    "            mean_squared_error(y_predict, y_test),\n",
    "            mean_squared_error(y_predict_train, y_train),\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"R^2 coefficient, test: {:.2f}, train: {:.2f}\".format(\n",
    "            r2_score(y_predict, y_test), r2_score(y_predict_train, y_train)\n",
    "        )\n",
    "    )\n",
    "    if plot_test:\n",
    "        sns.scatterplot(x=y_test, y=y_predict, alpha=0.5)\n",
    "        plt.show()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa60d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmw_train, bmw_val = train_test_split(bmw_cleaned, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bab936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cat_transformer_tuple = (\n",
    "    OneHotEncoder(),\n",
    "    make_column_selector(dtype_include=\"category\"),\n",
    ")\n",
    "ohe = make_column_transformer(cat_transformer_tuple, remainder=\"passthrough\")\n",
    "\n",
    "linreg = Pipeline(((\"one_hot\", ohe), (\"regressor\", LinearRegression())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04198be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_dependent(bmw_cleaned[[\"log price\", \"mileage\", \"year\"]], dependent=\"log price\")\n",
    "cross_validate(linreg, X, y, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e836e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_mean_and_std(scores):\n",
    "    \"\"\"Finds mean and standard deviations of scores from `cross_validate`,\n",
    "    and puts them in a dataframe.\"\"\"\n",
    "    scores = pd.DataFrame(scores)[[\"test_score\", \"train_score\"]]\n",
    "    mean = scores.mean().add_prefix(\"mean_\")\n",
    "    std = scores.std().add_prefix(\"std_\")\n",
    "    mean_std = pd.concat((mean, std))\n",
    "    return mean_std\n",
    "\n",
    "feature_cols = [\"mileage\", \"model\", \"year\", \"engineSize\", \"transmission\", \"fuelType\", \"mpg\", \"tax\"]\n",
    "#feature_cols = [\"mileage\", \"model\", \"year\", \"engineSize\", \"fuelType\", \"transmission\", \"mpg\", \"tax\"]\n",
    "linreg = Pipeline(((\"one_hot\", ohe), (\"regressor\", LinearRegression())))\n",
    "all_scores = {}\n",
    "for i in range(1, len(feature_cols) + 1):\n",
    "    cols = [\"log price\"] + feature_cols[:i]\n",
    "    X, y = split_dependent(bmw_cleaned[cols], dependent=\"log price\")\n",
    "    scores = cross_validate(linreg, X, y, return_train_score=True)\n",
    "    all_scores[cols[-1]] = scores_mean_and_std(scores)\n",
    "all_scores = pd.DataFrame(all_scores).T\n",
    "all_scores.index.name = \"Last added feature\"\n",
    "display(all_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd92acf",
   "metadata": {},
   "source": [
    "Here I cumulatively added features one by one, and look at the five-fold cross validation score from fitting a linear model. I see that only considering the `mileage` gives a low R^2 score of 0.432. Adding the car `model` improves it considerably, as does adding `year`. Further adding the remaining new car configuration features further improves the R^2 score. Adding the `mpg` and `tax` does not change the R^2 score. We therefore continue the analysis including only the `mileage` and the new car configuration features, but excluding `mpg` and `tax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0f4d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit_transform(bmw_cleaned)\n",
    "features = ohe.get_feature_names()\n",
    "for i, cat_col in enumerate(categorical_columns):\n",
    "    features = [\n",
    "        feature.replace(f\"onehotencoder__x{i}\", cat_col) for feature in features\n",
    "    ]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573c1b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_ = OneHotEncoder()\n",
    "ohe_.fit_transform(bmw_cleaned[categorical_columns])\n",
    "ohe_.get_feature_names(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0095ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=0.001)\n",
    "bmw_selected = bmw_cleaned[[\"log price\", \"mileage\"] + new_car_cols]\n",
    "bmw_selected = pd.get_dummies(bmw_selected, drop_first=True)\n",
    "linreg = fit_and_test_linear_model(bmw_selected, model=lasso)\n",
    "#print_linear_coeffs(features, linreg, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b03c6c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lasso = Pipeline(((\"one_hot\", ohe), (\"regressor\", Lasso())))\n",
    "\n",
    "cols = [\n",
    "    \"log price\",\n",
    "    \"mileage\",\n",
    "    \"model\",\n",
    "    \"year\",\n",
    "    \"engineSize\",\n",
    "    \"transmission\",\n",
    "    \"fuelType\",\n",
    "]\n",
    "param_grid = {\"regressor__alpha\": [0.0005, 0.001, 0.01, 0.1]}\n",
    "clf = GridSearchCV(estimator=lasso, param_grid=param_grid, return_train_score=True)\n",
    "X, y = split_dependent(bmw_cleaned[cols], dependent=\"log price\")\n",
    "clf.fit(X, y)\n",
    "display(\n",
    "    pd.DataFrame(clf.cv_results_)[\n",
    "        [\n",
    "            \"param_regressor__alpha\",\n",
    "            \"mean_test_score\",\n",
    "            \"mean_train_score\",\n",
    "            \"std_test_score\",\n",
    "            \"std_train_score\",\n",
    "        ]\n",
    "    ].set_index(\"param_regressor__alpha\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba1811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Pipeline(((\"one_hot\", ohe), (\"regressor\", Ridge(tol=1e-9))))\n",
    "\n",
    "param_grid = {\"regressor__alpha\": [0] + list(10**i for i in range(5))}\n",
    "clf = GridSearchCV(estimator=ridge, param_grid=param_grid, return_train_score=True)\n",
    "clf.fit(X, y)\n",
    "display(\n",
    "    pd.DataFrame(clf.cv_results_)[\n",
    "        [\n",
    "            \"param_regressor__alpha\",\n",
    "            \"mean_test_score\",\n",
    "            \"mean_train_score\",\n",
    "            \"std_test_score\",\n",
    "            \"std_train_score\",\n",
    "        ]\n",
    "    ].set_index(\"param_regressor__alpha\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e6153f",
   "metadata": {},
   "source": [
    "## Tree models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b666dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbr = GradientBoostingRegressor()\n",
    "bmw_selected = bmw_cleaned[[\"log price\", \"mileage\"] + new_car_cols]\n",
    "bmw_selected = pd.get_dummies(bmw_selected, drop_first=True)\n",
    "fit_and_test_model(bmw_selected, gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be30d144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor()\n",
    "bmw_selected = bmw_cleaned[[\"log price\", \"mileage\"] + new_car_cols]\n",
    "bmw_selected = pd.get_dummies(bmw_selected, drop_first=True)\n",
    "fit_and_test_model(bmw_selected, rfr, plot_test=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
